# **Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-Free Long Video Diffusion**  

ğŸš€ **Official Implementation of Ouroboros-Diffusion (AAAI 2025)**  

This repository provides the implementation of **Ouroboros-Diffusion**, a novel **tuning-free long video diffusion framework** designed to enhance **structural and subject consistency** in long video generation.  

ğŸ“„ **Our paper has been accepted at AAAI 2025!**  

[ğŸ“œ Paper (Arxiv)](https://arxiv.org/abs/2501.09019) | [ğŸ”— Project Page (Coming Soon)](TBD) | [ğŸ¥ Demo Videos (Coming Soon)](TBD)

---

## **ğŸ“ Overview**  
Current **tuning-free video diffusion** methods (e.g., FIFO-Diffusion) struggle with **long-term consistency**, leading to **flickering frames and subject appearance drift**. Ouroboros-Diffusion addresses this by introducing **three key components**:  

âœ… **Coherent Tail Latent Sampling** â†’ Ensures **structural continuity** by replacing independent Gaussian noise with a **low-frequency-preserving latent**.  
âœ… **Subject-Aware Cross-Frame Attention (SACFA)** â†’ Aligns **subject appearances across frames**, improving **short-term consistency**.  
âœ… **Self-Recurrent Guidance** â†’ Utilizes **historical frame embeddings** to **guide denoising**, ensuring **long-term subject coherence**.  

These innovations **significantly improve video consistency**, outperforming **StreamingT2V, FIFO-Diffusion, and FreeNoise** on the **VBench benchmark**.  

ğŸ“Š **Key Results**  
âœ” **Higher subject consistency**  
âœ” **Smoother motion transitions**  
âœ” **Reduced flickering & content drift**  

---

## **ğŸ› ï¸ Code Release Plan**  

ğŸ”¹ We will **first release three code demos**, each corresponding to one of the key components:  
1ï¸âƒ£ **Coherent Tail Latent Sampling**  
2ï¸âƒ£ **Subject-Aware Cross-Frame Attention (SACFA)**  
3ï¸âƒ£ **Self-Recurrent Guidance**  

ğŸ“… **Full implementation** is expected to be released **before March 15th, 2025**. Stay tuned! ğŸš€  

---

## **ğŸ“Œ Setup & Installation**  

### **1ï¸âƒ£ Install Dependencies**  
```bash
git clone https://github.com/your-repo/Ouroboros-Diffusion.git
cd Ouroboros-Diffusion
pip install -r requirements.txt
```

### **2ï¸âƒ£ Run Demo Codes**  
Each component has its own demo script:  
```bash
python demo_coherent_tail_latent.py  # Run Coherent Tail Latent Sampling
python demo_sacfa.py                 # Run Subject-Aware Cross-Frame Attention
python demo_self_recurrent.py         # Run Self-Recurrent Guidance
```

### **3ï¸âƒ£ Full Pipeline (Coming Soon)**  
The full Ouroboros-Diffusion pipeline will be available by **March 15th, 2025**.

---

## **ğŸ“Š Results & Evaluation**  

Ouroboros-Diffusion achieves **state-of-the-art performance** on the **VBench benchmark**, surpassing **FIFO-Diffusion, StreamingT2V, and FreeNoise** in:  
âœ… **Content Consistency**  
âœ… **Visual Fidelity**  
âœ… **Motion Smoothness**  
âœ… **Video-Text Alignment**  


---

## **ğŸ“Œ Citation**  

If you find this work useful, please consider citing:  

```bibtex
@inproceedings{chen2025ouroboros,
  title={Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-Free Long Video Diffusion},
  author={Chen, Jingyuan and Long, Fuchen and An, Jie and Qiu, Zhaofan and Yao, Ting and Luo, Jiebo and Mei, Tao},
  booktitle={AAAI},
  year={2025}
}
```

---

## **ğŸ“© Contact**  

For questions, feel free to open an issue or reach out:  
ğŸ“§ **Email:** jchen157@u.rochester.edu  
ğŸ¦ **Twitter:** TBD  

ğŸ”” **Stay updated!** Star â­ this repo and check back for the full code release! ğŸš€
